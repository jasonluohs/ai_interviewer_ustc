#è¿™é‡Œå¤„ç†TTSå’ŒASRçš„apiè°ƒç”¨
# modules/audio_processor.py
from openai import OpenAI
import os
import re
from pathlib import Path
from openai import OpenAI
 
# æ°¸è¿œä¸è¦åœ¨ä»£ç é‡Œå†™æ­»ç»å¯¹è·¯å¾„ï¼Œå°¤å…¶æ˜¯å¸¦ä¸­æ–‡çš„(è¡€çš„æ•™è®­)
# è¿™é‡Œä¿ç•™ä¸ºç©ºæˆ–é»˜è®¤å€¼å³å¯ï¼Œå®é™…ç”± app.py æ§åˆ¶
speech_file_path = "temp_audio_test.mp3" 

class TTS_no_stream:
    def __init__(self, api_key):
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.stepfun.com/v1"
        )
        self.default_voice = "cixingnansheng"

    def to_speech(self, text, output_path):
        """
        output_path: å¿…é¡»æ˜¯å®Œæ•´çš„æ–‡ä»¶è·¯å¾„ (str æˆ– Path å¯¹è±¡)
        """
        try:
            # 1. è·¯å¾„æ¸…æ´—ï¼šå¼ºåˆ¶è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼Œå¹¶ç»Ÿä¸€æ–œæ æ ¼å¼
            save_path = Path(output_path).resolve()
            
            # ğŸ è°ƒè¯•æ‰“å°ï¼šçœ‹çœ‹æœ€ç»ˆåˆ°åº•å­˜å“ªå„¿å»äº†
            print(f"DEBUG: æ­£åœ¨å°è¯•å†™å…¥æ–‡ä»¶ -> {save_path}")

            # 2. å‘èµ·è¯·æ±‚
            # âš ï¸ å…³é”®ä¿®å¤ï¼šæš‚æ—¶æ³¨é‡Šæ‰ 'style': 'ä¸¥è‚ƒ'
            # å¦‚æœåŠ ä¸Šè¿™ä¸ªè¿˜æŠ¥é”™ï¼Œè¯´æ˜ StepFun çš„ SDK åœ¨å¤„ç† JSON ä¸­æ–‡æ—¶æœ‰ Bug
            response = self.client.audio.speech.create(
                model="step-tts-mini",
                voice=self.default_voice,
                input=text,
                extra_body={
                    "volume": 1.0,
                    # "voice_label": {    <--- æš‚æ—¶æ³¨é‡Šæ‰è¿™é‡Œï¼Œæ’æŸ¥æ˜¯ä¸æ˜¯å®ƒçš„é”…
                        "style": "ä¸¥è‚ƒ"
                    # }
                }
            )
            # ä¸è¦ç”¨ response.stream_to_fileï¼Œé‚£ä¸ªé»‘ç›’æ–¹æ³•å®¹æ˜“å‡ºç¼–ç é—®é¢˜
            # æˆ‘ä»¬ç”¨ Python åŸç”Ÿçš„ 'wb' (äºŒè¿›åˆ¶å†™å…¥) æ¨¡å¼ï¼Œå…¼å®¹æ€§æœ€å¼º
            with open(save_path, "wb") as f:
                f.write(response.content)
            
            print(f"âœ… éŸ³é¢‘ä¿å­˜æˆåŠŸ")
            return True

        except Exception as e:
            print(f"âŒ TTS ç”Ÿæˆé”™è¯¯: {e}")
            # æ‰“å°é”™è¯¯ç±»å‹ï¼Œå¸®åŠ©åˆ¤æ–­
            print(f"é”™è¯¯ç±»å‹: {type(e)}")
            return False

# ä¸‹é¢çš„ chunking_tool ä¿æŒä¸å˜...
def chunking_tool(text):
    """
    å°† AI ç”Ÿæˆçš„æ–‡æœ¬æµåˆ‡åˆ†ä¸ºå®Œæ•´çš„å¥å­ï¼Œä»¥ä¾¿è§¦å‘å®æ—¶ TTSã€‚
    æ¶æ„æ€è€ƒï¼šæ­¤å‡½æ•°é€šå¸¸ä½äº modules/audio_processor.py ä¸­ï¼Œä½œä¸º TTS æµçš„å‰ç½®è¿‡æ»¤ã€‚
    """
    # 1. å®šä¹‰æ–­å¥æ ‡ç‚¹ï¼šå¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼ˆåŒ…å«ä¸­è‹±æ–‡ï¼‰
    # 2. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œåˆ‡åˆ†ï¼Œæ•è·ç»„ () ç¡®ä¿æ ‡ç‚¹ç¬¦å·è¢«ä¿ç•™åœ¨åˆ—è¡¨ä¸­
    punc_list = r'([ã€‚ï¼ï¼Ÿ.?!\n])'
    
    # åˆå§‹åˆ‡åˆ†
    raw_chunks = re.split(punc_list, text)
    
    combined_chunks = []
    # 3. å°†æ ‡ç‚¹ç¬¦å·åˆå¹¶å›å‰é¢çš„å¥å­
    for i in range(0, len(raw_chunks) - 1, 2):
        sentence = raw_chunks[i].strip()
        punctuation = raw_chunks[i+1]
        if sentence:
            combined_chunks.append(f"{sentence}{punctuation}")
    
    # å¤„ç†æœ€åä¸€æ®µå¯èƒ½æ²¡æœ‰æ ‡ç‚¹çš„æ–‡å­—ï¼ˆLLM æ­£åœ¨ç”Ÿæˆä¸­ï¼‰
    if len(raw_chunks) % 2 == 1:
        last_chunk = raw_chunks[-1].strip()
        if last_chunk:
            combined_chunks.append(last_chunk)
            
    return combined_chunks







# audio_processor.py - ä¿®å¤ç‰ˆæœ¬
import asyncio
import aiohttp
from typing import Optional
import tempfile
import os

async def audio_to_text(audio_file_path: str, api_key: str) -> Optional[str]:
    """å¼‚æ­¥è¯­éŸ³è½¬æ–‡æœ¬"""
    try:
        # å¼‚æ­¥è¯»å–æ–‡ä»¶
        audio_data = await asyncio.to_thread(_read_file, audio_file_path)
        if not audio_data:
            return None
        
        # å‡†å¤‡è¯·æ±‚
        data = aiohttp.FormData()
        data.add_field('model', 'step-asr')
        data.add_field('file', audio_data, 
                      filename=os.path.basename(audio_file_path),
                      content_type='audio/wav')
        data.add_field('language', 'zh')
        
        # å¼‚æ­¥APIè¯·æ±‚
        async with aiohttp.ClientSession() as session:
            headers = {"Authorization": f"Bearer {api_key}"}
            
            async with session.post(
                "https://api.stepfun.com/v1/audio/transcriptions",
                headers=headers,
                data=data,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                
                if response.status == 200:
                    result = await response.json()
                    return result.get('text', '').strip()
                else:
                    print(f"APIé”™è¯¯: {response.status}")
                    return None
                    
    except Exception as e:
        print(f"è½¬æ¢é”™è¯¯: {e}")
        return None

def _read_file(path: str) -> Optional[bytes]:
    """åŒæ­¥è¯»å–æ–‡ä»¶"""
    try:
        with open(path, 'rb') as f:
            return f.read()
    except:
        return None


async def record_audio_async(sample_rate: int = 16000) -> Optional[bytes]:
    """å¼‚æ­¥å½•éŸ³"""
    try:
        import sounddevice as sd
        import numpy as np
        
        # ç­‰å¾…å¼€å§‹
        await _async_input("")
        
        print("å¼€å§‹å½•éŸ³ï¼ŒæŒ‰å›è½¦é”®åœæ­¢...")
        
        # ä½¿ç”¨äº‹ä»¶æ§åˆ¶å½•éŸ³
        is_recording = True
        audio_chunks = []
        
        # éŸ³é¢‘å›è°ƒ
        def audio_callback(indata, frames, time_info, status):
            if is_recording:
                audio_int16 = (indata[:, 0] * 32767).astype(np.int16)
                audio_chunks.append(audio_int16.tobytes())
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œå½•éŸ³
        async def run_recording():
            with sd.InputStream(
                samplerate=sample_rate,
                channels=1,
                dtype='float32',
                callback=audio_callback,
                blocksize=int(sample_rate * 0.1)
            ):
                # ç­‰å¾…åœæ­¢
                await stop_event.wait()
        
        # åˆ›å»ºåœæ­¢äº‹ä»¶
        stop_event = asyncio.Event()
        recording_task = asyncio.create_task(run_recording())
        
        # ç­‰å¾…åœæ­¢è¾“å…¥
        async def wait_for_stop():
            await _async_input()
            stop_event.set()
        
        stop_task = asyncio.create_task(wait_for_stop())
        
        # æ˜¾ç¤ºè¿›åº¦
        start_time = asyncio.get_event_loop().time()
        
        while not stop_event.is_set():
            duration = asyncio.get_event_loop().time() - start_time
            print(f"\rå½•éŸ³ä¸­... {duration:.1f}ç§’", end="", flush=True)
            await asyncio.sleep(0.1)
        
        # åœæ­¢å½•éŸ³
        is_recording = False
        await recording_task
        await stop_task
        
        print(f"\nå½•éŸ³å®Œæˆï¼Œæ—¶é•¿: {duration:.1f}ç§’")
        
        if audio_chunks:
            return b''.join(audio_chunks)
        return None
        
    except Exception as e:
        print(f"å½•éŸ³é”™è¯¯: {e}")
        return None


async def _async_input(prompt: str = "") -> str:
    """å¼‚æ­¥è¾“å…¥"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, input, prompt)


async def save_audio_simple(audio_data: bytes, sample_rate: int = 16000) -> Optional[str]:
    """ç®€åŒ–ç‰ˆéŸ³é¢‘ä¿å­˜"""
    try:
        import wave
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
            temp_file = tmp.name
        
        # å†™å…¥WAVæ–‡ä»¶
        def write_wav():
            with wave.open(temp_file, 'wb') as wav:
                wav.setnchannels(1)
                wav.setsampwidth(2)
                wav.setframerate(sample_rate)
                wav.writeframes(audio_data)
        
        # åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ‰§è¡Œ
        await asyncio.to_thread(write_wav)
        
        return temp_file
        
    
    except Exception as e:
        print(f"ä¿å­˜é”™è¯¯: {e}")
        return None

async def cleanup_file(path: str):
    """å¼‚æ­¥æ¸…ç†æ–‡ä»¶"""
    if path and os.path.exists(path):
        await asyncio.to_thread(os.unlink, path)


async def voice_to_text(api_key: str, sample_rate: int = 16000) -> Optional[str]:
    """å®Œæ•´çš„è¯­éŸ³è½¬æ–‡æœ¬æµç¨‹"""
    print("å¼€å§‹è¯­éŸ³è¾“å…¥...")
    
    # 1. å¼‚æ­¥å½•éŸ³
    audio_data = await record_audio_async(sample_rate)
    if not audio_data:
        print("å½•éŸ³å¤±è´¥")
        return None
    
    # 2. å¼‚æ­¥ä¿å­˜
    temp_file = await save_audio_simple(audio_data, sample_rate)
    if not temp_file:
        print("ä¿å­˜å¤±è´¥")
        return None
    
    try:
        # 3. å¼‚æ­¥è½¬æ–‡æœ¬
        text = await audio_to_text(temp_file, api_key)
        return text
        
    finally:
        await cleanup_file(temp_file)


async def transcribe_file(file_path: str, api_key: str) -> Optional[str]:
    """è½¬å½•å·²æœ‰éŸ³é¢‘æ–‡ä»¶"""
    if not os.path.exists(file_path):
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None
    
    print(f"å¤„ç†æ–‡ä»¶: {file_path}")
    return await audio_to_text(file_path, api_key)