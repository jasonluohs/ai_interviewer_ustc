# 实现路径

---

* **llm_agent.py:** 关键函数llm_stream_chat(history,user_input),
  

* * 输入：其中history是前文的对话历史列表，格式为'role':'user'/'assistent'/'system','content':'具体的内容'，每一次调用ai api时都需要把整个history发进去
    
    * 输入举例：{'role':'system','content':'系统prompt写在这里'},{'role':'assistent','content':'ai的回复在这里'}
  
  * 输出：1.正常情况下输出整个ai回复。 2.有错误处理功能，若错误，会输出"抱歉，系统出了点小故障，然后把故障信息输出"

---

* **audio_processor.py:** 包括文字转语音（TTS）和语音转文字（ARS）两部分，关键函数（or类）**TTS_no_stream**,**voice_to_text(api_key: str, sample_rate: int = 16000) -> Optional[str]:**
  
  * TTS_no_stream类:定义了两个方法,一个 **__init__(self,api_key)** 还有一个**to_speech(self,text,output_path)** , __init__用于初始化，to_speech用于TTS，其中output_path必须是完整的文件路径，输出为True or False，表示是否成功。若成功，会把音频文件写入output_path
  
  * voice_to_text(api_key: str, sample_rate: int = 16000) -> Optional[str]:函数，用于异步语音转文本,返回一个str
  
  * chunking_tool(text)函数（不那么重要）用于断句,将ai生成的文本依照句号或问号断句,输入text为一个str,输出combined_chunks为一个字符串列表，为断句之后的句子。

---

前端要求：整合LLM,TTS,ARS，语音输入语音输出

---

config.py存了api


